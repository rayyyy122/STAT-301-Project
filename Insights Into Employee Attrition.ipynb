{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d32e28-d427-49f1-b9a2-3ee23ac118eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Insights Into Employee Attrition: Predictive Modeling With HR Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a2599-79c6-4831-abe4-2272e2548ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "## Data Overview & Relevance\n",
    "We have chosen to work with the HR Employee Attrition Dataset, which can be accessed [here](https://www.kaggle.com/datasets/rishikeshkonapure/hr-analytics-prediction/).\n",
    "\n",
    "This dataset is concerned with factors contributing to employee attrition. In the context of this dataset, attrition refers to an employee voluntarily leaving their place of work. There are a multitude of reasons an employee may attrit; according to a study by Firth et al., the most significant factors are job dissatisfaction, feelings of stress precipitated by the presence of job stressors, and lack of commitment to the organization (Firth et al., 2004).\n",
    "\n",
    "Employee attrition impedes business efficiency, disrupts current employees' ability to function, and incurs additional costs in hiring and training new employees. Predicting employee attrition is thus a valuable tool for any company. Understanding the factors that contribute to employee attrition helps companies identify and address employee retention issues, and use the findings of the analysis to inform their hiring process. It also benefits employees, by fostering an environment that prioritizes employment longevity (Boushay & Glynn, 2012). Boushay and Glynn delve deeper into the mutual advantages for both employers and employees that arise from mitigating attrition, as discussed in their 2012 paper.\n",
    "\n",
    "**Research Question:** What combination of environmental and demographic variables can predict the binary response variable, Attrition, most accurately?<br>\n",
    "<br>\n",
    "**Objective:** Identify an optimal prediction model that will offer valuable insights to employers during the employee selection process, and minimize the likelihood of future employee attrition.<br>\n",
    "<br>\n",
    "To achieve our stated objective, we plan to develop and compare multiple models, including a full model encompassing all available variables and selective models that includes a subset of relevant variables.\n",
    "\n",
    "## Data Description and Acknowledgements\n",
    "This dataset belongs to Rushikesh Konapure; the original source of the data is IBM.\n",
    "\n",
    "This dataset contains 35 variables and 1,470 observations. Each row represents a single employee from the same company.\n",
    "The variable metadata can be accessed [here](http://inseaddataanalytics.github.io/INSEADAnalytics/groupprojects/January2018FBL/IBM_Attrition_VSS.html).\n",
    "\n",
    "A comprehensive description of the data post-processing is provided under Clean & Tidy Data Characterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f313d-1e28-40d6-9401-4009f8ac84b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages({\n",
    "\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(reshape2)\n",
    "library(GGally)\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(car)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(broom)\n",
    "library(glmnet)\n",
    "library(leaps)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "library(caret)\n",
    "library(pROC)\n",
    "library(randomForest)\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c60d5d-f1c0-47c4-a567-59c7dde3f7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url <- \"https://raw.githubusercontent.com/vanessavalentine/Stat301_Group-9_Vanessa/main/HR-Employee-Attrition.csv\"\n",
    "data <- read.csv(url)\n",
    "head(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59031c6-6bfa-4821-a20f-d39cf3a91ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original Data variables\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c04ca-c8ee-4079-aef9-e01719b490a0",
   "metadata": {},
   "source": [
    "# Methods and Results\n",
    "## Data cleaning and wrangling\n",
    "To prime our data for subsequent analytical tasks, we performed the data cleaning & wrangling procedures outlined below.\n",
    "\n",
    "#### 1. Check for missing data\n",
    "Our data contained no missing values to be imputed.\n",
    "   \n",
    "#### 2. Excluding Irrelevant Variables\n",
    "* The variable **'EmployeeNumber'** is not pertinent to our analysis and will be excluded.\n",
    "\n",
    "* The variables **'DailyRate'** , **MonthlyRate** and **HourlyRate** will be omitted, as they are redundant given the presence of **'MonthlyIncome'**.\n",
    "\n",
    "* The columns **EmployeeCount**, **Over18**, and **StandardHours** hold constant values for every observation in the dataset. Features that do not vary across observations are not useful for further analysis. Consequently, they must be removed from the dataset.\n",
    "\n",
    "#### 3. Adjusting Ordinal Values\n",
    "Certain categorical variables are currently encoded as ordinal numbers (Likert Scale), and should be converted to their corresponding textual descriptors. This will enhance the interpretability of visual representations, and ensure clarity when we proceed to create dummy variables.\n",
    "\n",
    "#### 4. Recategorizing Variables\n",
    "* **StockOptionLevel:** ranging from 0 to 3, this variable lacks specific explanations. To enhance interpretability, we'll reclassify it: 0 as 'No' (no stock options granted), and 1 to 3 as 'Yes' (indicating stock options granted). It will also be renamed to **StockOption**.<br/>\n",
    "\n",
    "* **Age:** previously, the Age variable was continuous. We will modify it into 4 categories: 18-29, 30-39, 40-49, and 50 and above.<br/>\n",
    "\n",
    "#### 5. Transforming Categorical Variables\n",
    "All character variables in our dataset will be transformed to factors, ensuring that categorical data are properly recognized for analysis. This includes the response variable 'Attrition', since its possible values are 'Yes' or 'No'.\n",
    "\n",
    "Ordered levels will be assigned to variables measured on a Likert scale (e.g. Education, Job Satisfaction, Work-Life Balance), which allows for more meaningful statistical comparisons and visualizations that respect the inherent order of these ratings.\n",
    "\n",
    "#### 6. Renaming an Undescribed Category\n",
    "\n",
    "**JobLevel:** Job level is a categorical ordinal that ranges from [1,5]. However, the metadata doesn't specify what each level means. We will rename the categories as follows:<br>\n",
    "* 1 = Entry<br>\n",
    "* 2 = Intermediate<br>\n",
    "* 3 = Experienced<br>\n",
    "* 4 = Advanced<br>\n",
    "* 5 = Expert<br>\n",
    "\n",
    "This methodology is adopted based on [reference material](https://shr.ucsc.edu/compensation/career-tracks-classification-system/categories-and-levels-6-29-16.pdf) from the University of California, Santa Cruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b906076-790b-4d50-b91b-ece144d86d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1)\n",
    "sum(is.na(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf96fc-eea3-4c7b-9dc1-bd24a799aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2)\n",
    "for (col in names(data)) {\n",
    "    if (length(unique(data[[col]])) == 1) {\n",
    "        cat(\"Column\", col, \"has identical values. \\n\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf663c-66b5-437b-be1e-bc3089a5ec3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove all the variables identified above\n",
    "data <- data %>% select(-EmployeeNumber, -DailyRate, -StandardHours,\n",
    "                        -Over18, -MonthlyRate, -HourlyRate, -EmployeeCount) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9fd4a-57a6-4477-a586-eb8c7ff71ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3)\n",
    "data <- data %>%\n",
    "  mutate(Education = case_when(\n",
    "    Education == 1 ~ \"below-college\",\n",
    "    Education == 2 ~ \"college\",\n",
    "    Education == 3 ~ \"bachelor\",\n",
    "    Education == 4 ~ \"master\", \n",
    "    Education == 5 ~ \"PHD\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(EnvironmentSatisfaction = case_when(\n",
    "    EnvironmentSatisfaction == 1 ~ \"Low\",\n",
    "    EnvironmentSatisfaction == 2 ~ \"Medium\",\n",
    "    EnvironmentSatisfaction == 3 ~ \"High\",\n",
    "    EnvironmentSatisfaction == 4 ~ \"Very-High\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(JobInvolvement = case_when(\n",
    "    JobInvolvement == 1 ~ \"Low\",\n",
    "    JobInvolvement == 2 ~ \"Medium\",\n",
    "    JobInvolvement == 3 ~ \"High\",\n",
    "    JobInvolvement == 4 ~ \"Very-High\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(JobSatisfaction = case_when(\n",
    "    JobSatisfaction == 1 ~ \"Low\",\n",
    "    JobSatisfaction == 2 ~ \"Medium\",\n",
    "    JobSatisfaction == 3 ~ \"High\",\n",
    "    JobSatisfaction == 4 ~ \"Very-High\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(PerformanceRating = case_when(\n",
    "    PerformanceRating == 1 ~ \"Low\",\n",
    "    PerformanceRating == 2 ~ \"Good\",\n",
    "    PerformanceRating == 3 ~ \"Excellent\",\n",
    "    PerformanceRating == 4 ~ \"Outstanding\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(RelationshipSatisfaction = case_when(\n",
    "    RelationshipSatisfaction == 1 ~ \"Low\",\n",
    "    RelationshipSatisfaction == 2 ~ \"Good\",\n",
    "    RelationshipSatisfaction == 3 ~ \"Excellent\",\n",
    "    RelationshipSatisfaction == 4 ~ \"Outstanding\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(WorkLifeBalance = case_when(\n",
    "    WorkLifeBalance == 1 ~ \"Bad\",\n",
    "    WorkLifeBalance == 2 ~ \"Good\",\n",
    "    WorkLifeBalance == 3 ~ \"Better\",\n",
    "    WorkLifeBalance == 4 ~ \"Best\"\n",
    "  ))\n",
    "\n",
    "data <- data %>%\n",
    "  mutate(JobLevel = case_when(\n",
    "    JobLevel == 1 ~ \"Entry\",\n",
    "    JobLevel == 2 ~ \"Intermediate\",\n",
    "    JobLevel == 3 ~ \"Experienced\",\n",
    "    JobLevel == 4 ~ \"Advanced\", \n",
    "    JobLevel == 5 ~ \"Expert\"\n",
    "  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1613a-2d93-40fd-a12f-8f43d08fee63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4)\n",
    "data <- data %>%\n",
    "  mutate(StockOption = case_when(\n",
    "      StockOptionLevel == 0 ~ \"No\", \n",
    "      StockOptionLevel > 0 ~ \"Yes\"\n",
    "  )) %>% select(-StockOptionLevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195ff7b-aae2-4616-8e22-25bfd70077c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data <- data %>%\n",
    "  mutate(across(where(is.character), as.factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a195c-2bd8-4ae3-9cba-464ffe24f0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Steps 5) & 6)\n",
    "data <- data %>%\n",
    "  mutate(\n",
    "       # Make the ordinal / Likert scale as levels\n",
    "         Education = factor(Education, levels = c(\"below-college\", \"college\", \"bachelor\", \"master\", \"PHD\"), \n",
    "                            ordered = TRUE),\n",
    "         EnvironmentSatisfaction = factor(EnvironmentSatisfaction, levels = c(\"Low\", \"Medium\", \"High\", \"Very-High\")\n",
    "                                          , ordered = TRUE),\n",
    "         JobInvolvement = factor(JobInvolvement, levels = c(\"Low\", \"Medium\", \"High\", \"Very-High\")\n",
    "                                          , ordered = TRUE),\n",
    "         JobSatisfaction = factor(JobSatisfaction, levels = c(\"Low\", \"Medium\", \"High\", \"Very-High\")\n",
    "                                          , ordered = TRUE),\n",
    "         PerformanceRating = factor(PerformanceRating, levels = c(\"Low\", \"Good\", \"Excellent\", \"Outstanding\")\n",
    "                                          , ordered = TRUE),\n",
    "         RelationshipSatisfaction = factor(RelationshipSatisfaction, levels = c(\"Low\", \"Good\", \"Excellent\", \"Outstanding\")\n",
    "                                          , ordered = TRUE),\n",
    "         WorkLifeBalance = factor(WorkLifeBalance, levels = c(\"Bad\", \"Good\", \"Better\", \"Best\")\n",
    "                                          , ordered = TRUE), \n",
    "         # Level of the Job, where 1 is the lowest level and 5 is the highest\n",
    "         JobLevel = factor(JobLevel, levels = c(\"Entry\", \"Intermediate\", \"Experienced\", \"Advanced\", \"Expert\")\n",
    "                                          , ordered = TRUE),\n",
    "         # Travel frequency for job purposes\n",
    "         BusinessTravel = factor(BusinessTravel, levels = c(\"Non-Travel\", \"Travel_Rarely\", \"Travel_Frequently\")\n",
    "                                          , ordered = TRUE)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f52dd7-ab22-4642-93aa-fed5e9515447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f6f9c-334e-4560-b7ae-6dadba40cb28",
   "metadata": {},
   "source": [
    "### Clean & Tidy Data Characterization\n",
    "\n",
    "After cleaning & wrangling, our data consists of 28 variables (1 response variable and 27 independent variables), and 1,470 data points.\n",
    "\n",
    "The variables are characterized in more detail in the tables below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5bbb9-926d-45f8-b8b1-4d28887bfe61",
   "metadata": {},
   "source": [
    "#### Continuous & Discrete Integer Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ae943-cddb-4dce-b2f9-4b2cf2134381",
   "metadata": {},
   "source": [
    "| Name                     | Type     | Category | Range                                                |\n",
    "| ------------------------ | -------- | -------- | -------------                                               |\n",
    "| DistanceFromHome         | Integer  | Continuous | 1 to 29                                                     |\n",
    "| MonthlyIncome            | Integer  | Continuous | 1009 to 19999                                               |\n",
    "| NumCompaniesWorked       | Integer  | Continuous | 0 to 9                                                      |\n",
    "| PercentSalaryHike        | Integer  | Continuous | 11 to 25                                                    |\n",
    "| TotalWorkingYears        | Integer  | Continuous | 0 to 40                                                     |\n",
    "| TrainingTimesLastYear    | Integer  | Discrete | 0 to 6                                                       |\n",
    "| YearsAtCompany           | Integer  | Continuous | 0 to 40                                                     |\n",
    "| YearsInCurrentRole       | Integer  | Continuous | 0 to 18                                                     |\n",
    "| YearsSinceLastPromotion  | Integer  | Continuous | 0 to 15                                                     |\n",
    "| YearsWithCurrManager     | Integer  | Continuous | 0 to 17                                                     |\n",
    "| Age                      | Integer  | Continuous | -                                                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26957365-3340-4f0a-8d01-e75b83c27607",
   "metadata": {},
   "source": [
    "#### Categorical & Ordinal Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f6a7b-b0f6-4612-a68c-4935aeaa1d7e",
   "metadata": {},
   "source": [
    "| Name                     | Type     | Category | Cardinality | Unique Values                                 |\n",
    "| ------------------------ | -------- | -------- | ----------- | -----------------------------------------------------------------------------|\n",
    "| Attrition                | Categorical | Str   | 2           | Yes, No                                                                      |\n",
    "| Department               | Character| Categorical | 3           | Sales, Research & Development, Human Resources                               |\n",
    "| EducationField           | Character| Categorical | 6           | Life Sciences, Medical, Marketing, Technical Degree, Human Resources, Other   |\n",
    "| Gender                   | Character| Categorical | 2           | Female, Male                                                                  |\n",
    "| JobRole                  | Character| Categorical | 9           | Sales Executive, Research Scientist, Laboratory Technician, Manufacturing Director, Healthcare Representative, Manager, Sales Representative, Research Director, Human Resources |\n",
    "| MaritalStatus            | Character| Categorical | 3           | Divorced, Married, Single                                                    |\n",
    "| OverTime                 | Character| Categorical | 2           | Yes, No                                                                       |\n",
    "| StockOption              | Character| Categorical | 2           | Yes, No                                                                       |\n",
    "| BusinessTravel           | Character| Categorical | 3           | Non-Travel, Travel_Rarely, Travel_Frequently                                 |\n",
    "| Education                | Integer  | Ordinal  | 5           | below-college, college, bachelor, master, PHD                                 |\n",
    "| EnvironmentSatisfaction  | Integer  | Ordinal  | 4           | Low, Medium, High, Very-High                                                 |\n",
    "| JobInvolvement           | Integer  | Ordinal  | 4           | Low, Medium, High, Very-High                                                 |\n",
    "| JobLevel                 | Integer  | Ordinal  | 5           | Entry, Intermediate, Experienced, Advanced, Expert                            |\n",
    "| JobSatisfaction          | Integer  | Ordinal  | 4           | Low, Medium, High, Very-High                                                 |\n",
    "| PerformanceRating        | Integer  | Ordinal  | 4           | Low, Good, Excellent, Outstanding                                            |\n",
    "| RelationshipSatisfaction | Integer  | Ordinal  | 4           | Low, Good, Excellent, Outstanding                                            |\n",
    "| WorkLifeBalance          | Integer  | Ordinal  | 4           | Bad, Good, Better, Best                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f96280-21ca-4d1f-b491-4375754d2fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## a) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94448b9c-c22a-4400-bdc1-84dd186e8d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "\n",
    "data_continuous <- data %>% \n",
    "    select(DistanceFromHome, MonthlyIncome, NumCompaniesWorked,\n",
    "    PercentSalaryHike, TotalWorkingYears, TrainingTimesLastYear,\n",
    "    YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion,\n",
    "    YearsWithCurrManager, Age)\n",
    "\n",
    "correlation_matrix <- cor(data_continuous)\n",
    "\n",
    "correlation_melted <- melt(correlation_matrix)\n",
    "\n",
    "ggplot(data = correlation_melted, aes(x = Var1, y = Var2)) +\n",
    "  geom_tile(aes(fill = value)) +\n",
    "  scale_fill_gradient(low = \"blue\", high = \"red\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "  coord_fixed(ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a824bc5-872d-45f9-a765-9b4ae151c86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=12)\n",
    "\n",
    "data %>%\n",
    "select(Attrition, DistanceFromHome, MonthlyIncome, NumCompaniesWorked,PercentSalaryHike,YearsAtCompany, YearsSinceLastPromotion, Age, JobSatisfaction,WorkLifeBalance, RelationshipSatisfaction,OverTime) %>%\n",
    "    ggpairs(aes(color = Attrition), lower = \"blank\", legend = 1,\n",
    "    diag = list(continuous = wrap(\"densityDiag\", alpha = 0.5))) +\n",
    "    ggtitle(\"Final Visualization: Correlation and Distribution of Selected Variables by Attrition\") +\n",
    "    theme(legend.position = \"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4362b4f-faed-4d05-a24c-5782b64f7f25",
   "metadata": {},
   "source": [
    "#### Brief description of the chosen continuous variables and their plots:\n",
    "\n",
    "* **DistanceFromHome:** Slightly higher median values for those who left the company (Yes Attrition), which might imply that longer commutes may correlate with a higher likelihood of leaving the job. \n",
    "* **MonthlyIncome:** Hourly rate does not show a clear distinction between those who stayed and those who left. \n",
    "* **NumCompaniesWorked:** Employees who have worked at more companies tend to attrit more, suggesting a potentially persistent pattern of jobhopping.\n",
    "* **PercentSalaryHike:** Salary hikes seems to be constant between those who attrited and those who didn't. \n",
    "* **TotalWorkingYears:** Employees with fewer total working years have a higher tendency to leave, potentially reflecting early-career job exploration. \n",
    "* **YearsAtCompany:** Those who left generally have fewer years at the company, suggesting that those who have stayed longer are less likely to seek employment elsewhere.\n",
    "* **YearsSinceLastPromotion:** A higher concentration of individuals with a recent promotion in the group that stayed, hinting that promotions may contribute to employee retention. \n",
    "* **Age:** A younger workforce appears to be leaving more, which might relate to career exploration or lesser attachment to the company. \n",
    "* **JobSatisfaction:** Lower job satisfaction levels are visibly associated with higher attrition, suggesting the importance of job satisfaction in employee retention.\n",
    "* **WorkLifeBalance:** Poor work-life balance is subtly associated with higher attrition, suggesting it plays a role in attrition. \n",
    "* **RelationshipSatisfaction:** Lower levels of relationship satisfaction are seen in those who left, which could contribute to an uncomfortable work environment leading to higher attrition. \n",
    "* **OverTime:** A clear pattern where employees who have more overtime are more likely to leave, which might point towards work-life imbalance as reasons for attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1f0b1-fabd-44f8-9ce9-6d2c32003c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical variables with factor levels\n",
    "data_categorical <- data %>%\n",
    "  select_if(function(x) is.factor(x))\n",
    "\n",
    "factor_vars <- names(data_categorical)[sapply(data_categorical, is.factor)]\n",
    "\n",
    "# Create a function to generate and display bar plots\n",
    "generate_and_display_bar_plot <- function(var_name) {\n",
    "  melted_data <- tidyr::gather(data_categorical, key = \"variable\", value = \"value\", var_name)\n",
    "    g <- ggplot(melted_data, aes(x = value)) +\n",
    "    geom_bar() +\n",
    "    facet_wrap(~ variable, scales = \"free\") +\n",
    "    theme_minimal() +\n",
    "    labs(title = paste(\"Barplot of Counts for\", var_name),\n",
    "         x = \"Value\",\n",
    "         y = \"Count\")\n",
    "    print(g)\n",
    "}\n",
    "            \n",
    "options(repr.plot.width = 5, repr.plot.height = 3) \n",
    "\n",
    "# Generate and display separate bar plots for each factor variable\n",
    "for (var in factor_vars) {\n",
    "  generate_and_display_bar_plot(var)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7cc5b-bb3b-43cf-bde0-1e8ebd4536a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Insight from the visualization\n",
    "\n",
    "#### Brief descriptions of the distributions for categorical variables:**\n",
    "\n",
    "- **Attrition:** many more employees attritted than not; 1233:237\n",
    "- **BusinessTravel:** most employees do not have to travel frequently, but if they do have to travel, it is freuqent\n",
    "- **Department:** Biggest department is R&D, then HR, then sales\n",
    "- **Education:** most employees have a bachelors or masters as their highest level of education\n",
    "- **EducationField:** most employees studied a non-listed field, or marketing\n",
    "- **EnvironmentSatisfaction:** most employees have high or very high environment satisfaction\n",
    "- **Gender:** there are more male than female employees, but not by a large margin; 588:882\n",
    "- **JobInvolvement:** most employees rate themselves as having a highly involved job\n",
    "- **JobLevel:** most employees have a level 1- or 2-ranked job\n",
    "- **JobRole:** the most common job roles are research director, Sales rep, and lab tech; the least common was research scientist\n",
    "- **JobSatisfaction:** most employees rate their job satisfaction as High or Very High\n",
    "- **MaritalStatus:** most employees are married; second most frequent status is divorced; third is single\n",
    "- **OverTime:** most employees work overtime; 1054:416\n",
    "- **RelationshipSatisfacton:** most employees rate their relationship satisfaction as High or Very High\n",
    "- **StockOptionLevel:** most employees are given stock option level 1 or 2\n",
    "- **WorkLifeBalance:** most employees rate their work-life balance as High\n",
    "- **StockOption:** More employees get stock option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87be343-09b6-40cd-8d09-351dac87a514",
   "metadata": {},
   "source": [
    "## b) Methods: Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77c59b-a65c-4b60-8912-5415ab0b6887",
   "metadata": {},
   "source": [
    "To address our stated research question, we will employ two modeling techniques: logistic regression and random forest. Because the data contains 26 potential predictor variables, the use of LASSO for feature selection is a critical component of our methodology. By implementing LASSO, we can efficiently identify and retain only the most significant variables. The selection of the most appropriate model will be based on several criteria, including the analysis of ROC curves, prediction accuracy, and AUC. These metrics will guide us in choosing the model that best fits our data and provides the most reliable predictions.\n",
    "\n",
    "Our exploratory data analysis revealed the presence of multicollinearity and non-normality. Multicollinearity could lead to unreliable parameter estimates in the models. While LASSO can help in reducing the effects of multicollinearity by shrinking coefficients, it may not be entirely effective if multicollinearity is severe. Non-normality, on the other hand, violates the assumption of normality. As a result, the efficiency and accuracy of LASSO regression can be compromised when dealing with non-normally distributed data. To address this, we might employ data transformations (log transform and square root transform).\n",
    "\n",
    "Train and test data will be established using a 70/30 split. Our approach will initially employ LASSO for feature selection, followed by the development of various modeling techniques. While LASSO might be sufficient enough to mitigate multicollinearity during feature selection, it doesn't fully address issues related to strong multicollinearity and non-normality; a thorough approach, including extra preliminary steps for treating outliers and implementing methods to manage multicollinearity, is essential to ensure optimal performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0c402-8313-4bd6-8c1d-54918c66553d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We remove YearsWithCurrManager because it highly correlated with a lot of variables\n",
    "data_clean <- data %>% select(Attrition, DistanceFromHome, MonthlyIncome, NumCompaniesWorked, \n",
    "                      PercentSalaryHike, TotalWorkingYears, TrainingTimesLastYear,\n",
    "                      YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion,\n",
    "                       Age, BusinessTravel, Department, Education, \n",
    "                      EducationField, EnvironmentSatisfaction, Gender, JobInvolvement,\n",
    "                      JobLevel, JobRole, JobSatisfaction, MaritalStatus, OverTime,\n",
    "                      PerformanceRating, RelationshipSatisfaction, WorkLifeBalance, StockOption)\n",
    "# make attrition as numeric so that we can use it for lasso\n",
    "data_clean$Attrition <- as.numeric(data_clean$Attrition)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ecc91-9f71-4a3f-8bb3-399ba76fdb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#perform transform to normalize data\n",
    "data_clean <- data_clean %>%\n",
    "                       mutate(\n",
    "                         Age = log(Age),\n",
    "                         MonthlyIncome = log(MonthlyIncome),\n",
    "                         TotalWorkingYears = sqrt(TotalWorkingYears),\n",
    "                         YearsInCurrentRole = sqrt(YearsInCurrentRole), \n",
    "                         YearsSinceLastPromotion = sqrt(YearsSinceLastPromotion),\n",
    "                         PercentSalaryHike = log(PercentSalaryHike)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc05e00-8cc4-4a29-bf5b-e067a3d44cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train test split \n",
    "set.seed(4321) # Do not change this\n",
    "\n",
    "attrition_split <- initial_split(data_clean, prop = 0.7, strata = Attrition)\n",
    "attrition_selection <- training(attrition_split)\n",
    "attrition_inference <- testing(attrition_split)\n",
    "\n",
    "# Create model matrix for the predictors with one-hot encoding (dummy variable)\n",
    "predictors <- model.matrix(~ . -1, data = attrition_selection %>% select(-Attrition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2ba78-9f9c-4b6a-8aba-61f21752871f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_matrix_X_train <- model.matrix(Attrition ~ ., attrition_selection)[, -1]\n",
    "matrix_Y_train <- as.matrix(attrition_selection$Attrition, ncol = 1)\n",
    "\n",
    "model_matrix_X_test <- model.matrix(Attrition ~ ., attrition_inference)[, -1]\n",
    "matrix_Y_test<- as.matrix(attrition_inference$Attrition, ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed5a8c-efa9-40a2-a604-c05fdac83c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ordinary logistic model\n",
    "set.seed(4321)\n",
    "attrition_logistic_model <- \n",
    "    glm(\n",
    "        formula = Attrition ~ .,\n",
    "        data = attrition_selection,\n",
    "        family = binomial)\n",
    "ordinary_predicted_probabilities <- predict(attrition_logistic_model, newdata = attrition_inference, type = \"response\")\n",
    "\n",
    "\n",
    "ordinary_predicted_classes <- ifelse(ordinary_predicted_probabilities >= 0.5, 1, 0)\n",
    "\n",
    "ordinary_conf_mat <- confusionMatrix(data = as.factor(ordinary_predicted_classes),\n",
    "                reference = as.factor(attrition_inference$Attrition),\n",
    "                positive ='1')\n",
    "ordinary_conf_mat\n",
    "ordinary_accuracy <- ordinary_conf_mat$overall[\"Accuracy\"]\n",
    "ordinary_roc <- roc(response = attrition_inference$Attrition, predictor = ordinary_predicted_probabilities)\n",
    "ordinary_auc <- auc(ordinary_roc)\n",
    "ordinary_aic <- AIC(attrition_logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34428ff-5abe-4c7c-a7f1-9945d66c78af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use lasso to select variables\n",
    "set.seed(4321)\n",
    "\n",
    "attrition_cv_lambda_LASSO <-\n",
    "    cv.glmnet(model_matrix_X_train, \n",
    "              matrix_Y_train, \n",
    "              alpha=1,\n",
    "              family = \"binomial\",\n",
    "              type.measure = \"auc\",\n",
    "              nfolds = 5 \n",
    "             )\n",
    "\n",
    "attrition_cv_lambda_LASSO\n",
    "\n",
    "attrition_lambda_1se_AUC_LASSO <- round(attrition_cv_lambda_LASSO$lambda.1se, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41409535-4197-4a37-bd83-92f71e01f7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract coefficient for lasso logistic regression\n",
    "set.seed(4321)\n",
    "attrition_LASSO_1se_AUC <- glmnet(\n",
    "  x = model_matrix_X_train, y = matrix_Y_train,\n",
    "  alpha = 1,\n",
    "  family = \"binomial\",\n",
    "  lambda = attrition_lambda_1se_AUC_LASSO\n",
    ")\n",
    "\n",
    "attrition_LASSO_1se_AUC\n",
    "coef(attrition_LASSO_1se_AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77749528-25c3-47ea-ab3f-0a2d0c2fed51",
   "metadata": {},
   "source": [
    "##### Based on LASSO, we will remove \"PerformanceRating\", \"EducationField\", \"EducationField\", \"Education\", \"YearsSinceLastPromotion\", \"YearsAtCompany\", \"TotalWorkingYears\", \"TrainingTimesLastYear\", \"PercentSalaryHike\" because its coefficent have been shrunk to zero. This means that it is not significantly impactful in predicting attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768e1b8-0ad7-446e-82c1-968f9cc83e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(4321) # Do not change this\n",
    "\n",
    "attrition_split <- initial_split(data_clean, prop = 0.7, strata = Attrition)\n",
    "attrition_selection <- training(attrition_split)\n",
    "attrition_inference <- testing(attrition_split)\n",
    "\n",
    "\n",
    "attrition_selection <- attrition_selection %>% select(-PerformanceRating, -EducationField, -Education, -YearsSinceLastPromotion,\n",
    "                                                      -YearsAtCompany, -TrainingTimesLastYear,-PercentSalaryHike )\n",
    "attrition_inference <- attrition_inference %>% select(-PerformanceRating, -EducationField, -Education, -YearsSinceLastPromotion,\n",
    "                                                      -YearsAtCompany, -TrainingTimesLastYear,-PercentSalaryHike )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226c008-5e22-43d9-9eb6-e22684fe865d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ordinary logistic model\n",
    "log_attrition_lasso <- \n",
    "    glm(\n",
    "        formula = Attrition ~ .,\n",
    "        data = attrition_selection,\n",
    "        family = binomial)\n",
    "\n",
    "summary(log_attrition_lasso)\n",
    "\n",
    "log_attrition_lasso_result  <-\n",
    "    tidy(log_attrition_lasso) %>% \n",
    "    mutate(exp.estimate = exp(estimate)) %>% \n",
    "    mutate_if(is.numeric, round, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546383d-3d61-42a8-992b-84299ee3e2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso logistic model\n",
    "lasso_predicted_probabilities <- predict(log_attrition_lasso, newdata = attrition_inference, type = \"response\")\n",
    "\n",
    "lasso_predicted_classes <- ifelse(lasso_predicted_probabilities >= 0.5, 1, 0)\n",
    "\n",
    "lasso_conf_mat<- confusionMatrix(data = as.factor(lasso_predicted_classes),\n",
    "                reference = as.factor(attrition_inference$Attrition),\n",
    "                positive ='1')\n",
    "lasso_conf_mat\n",
    "\n",
    "lasso_accuracy <-lasso_conf_mat$overall[\"Accuracy\"]\n",
    "lasso_roc <- roc(response = attrition_inference$Attrition, predictor = lasso_predicted_probabilities)\n",
    "lasso_auc <- auc(lasso_roc)\n",
    "lasso_aic <- AIC(log_attrition_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41749ef3-1dd9-4dc3-b589-819454cb4b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "set.seed(4321)\n",
    "attrition_selection$Attrition <- as.factor(attrition_selection$Attrition)\n",
    "attrition_inference$Attrition <- as.factor(attrition_inference$Attrition)\n",
    "\n",
    "random_forest_model <- randomForest(Attrition ~ ., data = attrition_selection, ntree = 500)\n",
    "rf_predictions <- predict(random_forest_model, newdata = attrition_inference)\n",
    "\n",
    "rf_conf_matrix <- confusionMatrix(rf_predictions, attrition_inference$Attrition)\n",
    "print(rf_conf_matrix)\n",
    "\n",
    "rf_probabilities <- predict(random_forest_model, newdata = attrition_inference, type = \"prob\")\n",
    "rf_prob_of_positive_class <- rf_probabilities[, \"1\"]\n",
    "rf_accuracy <-rf_conf_matrix$overall[\"Accuracy\"]\n",
    "rf_roc <- roc(as.numeric(attrition_inference$Attrition), rf_prob_of_positive_class)\n",
    "rf_auc <- auc(rf_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa2916-3e78-4b23-9aa5-ebf53d93f198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_comparison <- data.frame(\n",
    "  Model = c(\"Ordinary Logistic Regression\", \"LASSO Logistic Regression\", \"Random Forest\"),\n",
    "  AIC = c(AIC(attrition_logistic_model), AIC(log_attrition_lasso), NA),  # NA for Random Forest\n",
    "  AUC = c(ordinary_auc, lasso_auc, rf_auc),\n",
    "  Prediction_Accuracy = c(ordinary_accuracy, lasso_accuracy, rf_accuracy)\n",
    ")\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d22dbc-1f4e-4776-acae-4234da02cd3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=7)\n",
    "plot(ordinary_roc, main = \"ROC Curves Comparison\", col = \"blue\", lwd = 2)\n",
    "plot(lasso_roc, col = \"red\", add = TRUE, lwd = 2)\n",
    "plot(rf_roc, col = \"green\", add = TRUE, lwd = 2)\n",
    "\n",
    "legend(\"bottomright\", legend = c(\"Ordinary Logistic\", \"LASSO Logistic\", \"Random Forest\"),\n",
    "       col = c(\"blue\", \"red\", \"green\"), lwd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc4b4f-6d13-4a0a-a89c-ea6826e00405",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Discussion\n",
    "\n",
    "Our comparative study of classification models utilized ordinary logistic regression, logistic regression with LASSO feature selection, and a random forest model. The LASSO model performed the best with respect to prediction accuracy, achieving a score of 90.50%, followed by the ordinary logistic regression at 88.91%, while the random forest model scored 85.97% accuracy. \n",
    "\n",
    "Assessing the models' discriminative capabilities with AUC revealed that the ordinary logistic regression model leads with an AUC of 0.8789, indicating superior performance in differentiating between instances of attrition and non-attrition. The LASSO model shows slightly reduced effectiveness with an AUC of 0.8651, while the random forest model ranks third with an AUC of 0.8424. \n",
    "\n",
    "The ROC indicates that the ordinary logistic regression model is the most proficient model, followed by the LASSO model, with the random forest model being the least capable.\n",
    "\n",
    "Considering model complexity and goodness-of-fit as indicated by the AIC, the LASSO model appears to offer the most parsimonious fit with the lowest AIC value, a metric not applicable to the non-parametric random forest model. While LASSO logistic regression offers the best balance between accuracy and model simplicity, ordinary logistic regression exhibits the highest discriminative ability.\n",
    "\n",
    "In the LASSO model, we used the variables\n",
    "- `DistanceFromHome`\n",
    "- `MonthlyIncome`\n",
    "- `NumCompaniesWorked`\n",
    "- `YearsInCurrentRole`\n",
    "- `Age`\n",
    "- `DepartmentResearch & Development`\n",
    "- `DepartmentSales`\n",
    "- `MaritalStatusSingle`\n",
    "- `OverTimeYes`\n",
    "- `StockOptionYes`\n",
    "\n",
    "and some levels in our created dummy variables: \n",
    "- `BusinessTravel.L`\n",
    "- `EnvironmentSatisfaction.L`\n",
    "- `JobInvolvement.L`, `JobLevel.Q`\n",
    "- `JobLevel.C`\n",
    "- `JobLevel^4`\n",
    "- `JobRoleLaboratory Technician`\n",
    "- `JobRoleResearch Director`\n",
    "- `RelationshipSatisfaction.L`\n",
    "- `RelationshipSatisfaction.Q`\n",
    "- `WorkLifeBalance.Q`\n",
    "\n",
    "Most of these predictor variables aligned with our expectations with respect to their significance in predicting employee attrition, with the exception of the two job roles, laboratory technician and research director. Before fitting the model, we believed that job level could affect attrition rate, but not job role. Our results indicate possible problems with these two job roles, since all other job positions are unrelated. The achieved prediction accuracy exceeded our initial target. Attaining a prediction accuracy over 95% is not practical or easy, so our goal from the outset was to achieve a prediction accuracy of 90%.\n",
    "\n",
    "The performance of our model can be further enhanced. Only a subset of variables are eliminated via LASSO; the resulting model is complicated and prone to overfitting. Leave-one-out or K-fold Cross-validation are methods that could improve variable selection performance. Though we did incorporate dummy variables appropriately, interaction terms were not taken into account. Given the quantity of predictors that are similar or related, interaction could have significant effects on model accuracy.\n",
    "\n",
    "The research objective of this project has many practical applications. Modeling the attrition of employees against multiple factors allows one to examine the probability of attrition across various work environments. This could offer valuable insights to managers or leaders on methods to minimize costly employee attrition and attract high-quality talent from the job market. Additionally, our approach can be extended to many domains, such as organizations or educational institutions, to explore the impact of factors on students or participants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907378f0-0eb1-49ed-841d-cd0c2e26e21c",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69657a6d-2d1b-4e9d-85c9-5485e7bba207",
   "metadata": {},
   "source": [
    "Firth, L., Mellor, D., Moore, K. A., & Loquet, C. (2004). How Can Managers Reduce Employee Intention to Quit? *Journal of Managerial Psychology*, 19(2), 170–187. https://doi.org/10.1108/02683940410526127\n",
    "\n",
    "Boushey, H., & Glynn, J. (2012). There Are Significant Business Costs to Replacing Employees. *Center for American Progress*, 1–9. http://cdn.americanprogress.org/wp-content/uploads/2012/11/CostofTurnover.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
